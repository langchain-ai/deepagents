"""HTCondor batch farm integration for ChATLAS agents.

This module provides utilities for submitting ChATLAS agent jobs to CERN's HTCondor
batch farm system. It generates HTCondor submit files and handles job submission.

Reference: https://batchdocs.web.cern.ch/local/submit.html
"""

import logging
import re
import shlex
import subprocess
from pathlib import Path
from typing import Optional, Dict, Any

logger = logging.getLogger(__name__)


class HTCondorJobSubmitter:
    """HTCondor batch job submitter for ChATLAS agents."""

    def __init__(
        self,
        docker_image: str = "python:3.13-slim",
        output_dir: Optional[Path] = None,
    ):
        """Initialize HTCondor job submitter.

        Args:
            docker_image: Docker image to use for the agent sandbox
            output_dir: Directory for job output files (default: ./htcondor_jobs)
        """
        self.docker_image = docker_image
        self.output_dir = output_dir or Path("./htcondor_jobs")
        self.output_dir.mkdir(parents=True, exist_ok=True)

    def generate_submit_file(
        self,
        job_name: str,
        prompt: str,
        config_file: Optional[str] = None,
        env_vars: Optional[Dict[str, str]] = None,
        **kwargs: Any,
    ) -> Path:
        """Generate HTCondor submit file for an agent job.

        Args:
            job_name: Name for the batch job
            prompt: Input prompt for the agent
            config_file: Optional path to agent configuration YAML
            env_vars: Optional environment variables to pass to the job
            **kwargs: Additional HTCondor submit parameters

        Returns:
            Path to the generated submit file
        """
        # Create job-specific directory
        job_dir = self.output_dir / job_name
        job_dir.mkdir(parents=True, exist_ok=True)

        # Build the command to run the agent with proper shell escaping
        cmd_parts = ["python", "-m", "chatlas_agents.cli", "run"]
        
        if config_file:
            cmd_parts.extend(["--config", config_file])
        
        cmd_parts.extend(["--input", prompt])
        cmd_parts.append("--docker-sandbox")
        cmd_parts.extend(["--docker-image", self.docker_image])

        # Properly escape each argument for shell execution
        command = " ".join(shlex.quote(part) for part in cmd_parts)

        # Prepare environment variables
        # HTCondor format: environment = "VAR1=value1 VAR2=value2"
        # Keys are plain, values may contain special chars so we escape them
        env_list = []
        if env_vars:
            # Valid environment variable pattern: POSIX standard allows letters, digits, underscores
            # Must start with letter or underscore
            valid_var_pattern = re.compile(r'^[A-Za-z_][A-Za-z0-9_]*$')
            
            for key, value in env_vars.items():
                # Validate key is a valid environment variable name
                if not valid_var_pattern.match(key):
                    logger.warning(f"Skipping invalid environment variable name: {key}")
                    continue
                # Escape value for shell safety (within the double-quoted environment string)
                # Escape $ and " characters that have special meaning in HTCondor/shell
                safe_value = value.replace('"', '\\"').replace('$', '\\$')
                env_list.append(f"{key}={safe_value}")

        # Generate submit file content following CERN HTCondor format
        submit_content = f"""# HTCondor submit file for ChATLAS agent job: {job_name}
# Generated by chatlas-agents HTCondor integration
# Reference: https://batchdocs.web.cern.ch/local/submit.html

# Executable and arguments
executable = /bin/bash
arguments = -c "{command}"

# Docker universe for containerized execution
universe = docker
docker_image = {self.docker_image}

# Output, error, and log files
output = {job_dir}/job.$(ClusterId).$(ProcId).out
error = {job_dir}/job.$(ClusterId).$(ProcId).err
log = {job_dir}/job.$(ClusterId).log

# Environment variables
"""
        
        if env_list:
            submit_content += f'environment = "{" ".join(env_list)}"\n'
        else:
            submit_content += "# No environment variables specified\n"

        submit_content += """
# Resource requirements and job preferences
"""
        
        # Add resource requirements with defaults
        submit_content += f"request_cpus = {kwargs.get('request_cpus', 1)}\n"
        submit_content += f"request_memory = {kwargs.get('request_memory', '2GB')}\n"
        submit_content += f"request_disk = {kwargs.get('request_disk', '1GB')}\n"
        
        # Add any additional parameters (skip the resource requirements we already added)
        for key, value in kwargs.items():
            if key not in ['request_cpus', 'request_memory', 'request_disk']:
                submit_content += f"{key} = {value}\n"

        # Add queue command
        submit_content += "\n# Queue the job\nqueue 1\n"

        # Write submit file
        submit_file = job_dir / f"{job_name}.sub"
        submit_file.write_text(submit_content)
        
        logger.info(f"Generated HTCondor submit file: {submit_file}")
        return submit_file

    def submit_job(
        self,
        job_name: str,
        prompt: str,
        config_file: Optional[str] = None,
        env_vars: Optional[Dict[str, str]] = None,
        dry_run: bool = False,
        **kwargs: Any,
    ) -> Optional[str]:
        """Submit a ChATLAS agent job to HTCondor.

        Args:
            job_name: Name for the batch job
            prompt: Input prompt for the agent
            config_file: Optional path to agent configuration YAML
            env_vars: Optional environment variables to pass to the job
            dry_run: If True, only generate submit file without submitting
            **kwargs: Additional HTCondor submit parameters

        Returns:
            Job cluster ID if submitted, None if dry run or on error
        """
        # Generate submit file
        submit_file = self.generate_submit_file(
            job_name=job_name,
            prompt=prompt,
            config_file=config_file,
            env_vars=env_vars,
            **kwargs,
        )

        logger.info(f"Submit file created at: {submit_file}")

        if dry_run:
            logger.info("Dry run mode - submit file generated but not submitted")
            return None

        # Submit to HTCondor
        try:
            result = subprocess.run(
                ["condor_submit", str(submit_file)],
                capture_output=True,
                text=True,
                check=True,
            )
            
            # Parse cluster ID from output
            # Typical output: "1 job(s) submitted to cluster 12345."
            output = result.stdout.strip()
            logger.info(f"HTCondor submission output: {output}")
            
            # Extract cluster ID
            cluster_id = None
            if "submitted to cluster" in output:
                parts = output.split("cluster")
                if len(parts) > 1:
                    cluster_id = parts[1].strip().rstrip(".")
            
            return cluster_id

        except subprocess.CalledProcessError as e:
            logger.error(f"Failed to submit job to HTCondor: {e.stderr}")
            raise RuntimeError(f"HTCondor submission failed: {e.stderr}") from e
        except FileNotFoundError:
            logger.error("condor_submit command not found. Is HTCondor installed?")
            raise RuntimeError(
                "HTCondor is not installed or condor_submit is not in PATH"
            ) from None

    def query_job_status(self, cluster_id: str) -> Optional[str]:
        """Query the status of an HTCondor job.

        Args:
            cluster_id: HTCondor cluster ID

        Returns:
            Job status information as string, or None on error
        """
        try:
            result = subprocess.run(
                ["condor_q", cluster_id],
                capture_output=True,
                text=True,
                check=True,
            )
            return result.stdout
        except subprocess.CalledProcessError as e:
            logger.error(f"Failed to query job status: {e.stderr}")
            return None
        except FileNotFoundError:
            logger.error("condor_q command not found. Is HTCondor installed?")
            return None

    def remove_job(self, cluster_id: str) -> bool:
        """Remove an HTCondor job from the queue.

        Args:
            cluster_id: HTCondor cluster ID

        Returns:
            True if successful, False otherwise
        """
        try:
            subprocess.run(
                ["condor_rm", cluster_id],
                capture_output=True,
                text=True,
                check=True,
            )
            logger.info(f"Removed job {cluster_id} from queue")
            return True
        except subprocess.CalledProcessError as e:
            logger.error(f"Failed to remove job: {e.stderr}")
            return False
        except FileNotFoundError:
            logger.error("condor_rm command not found. Is HTCondor installed?")
            return False
